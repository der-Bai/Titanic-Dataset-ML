{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "950dc2f5",
   "metadata": {},
   "source": [
    "Nach diesem [Beispiel](https://www.kaggle.com/code/arthurtok/introduction-to-ensembling-stacking-in-python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e97390ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Funktionen\n",
    "def transform_data(df:pd.DataFrame):\n",
    "    # Now the names...\n",
    "    # First, seperate the first and last name\n",
    "    df[[\"LastName\", \"FirstName_tmp\"]] = df[\"Name\"].str.split(\",\", expand=True)\n",
    "    \n",
    "    # Now the salutation forms\n",
    "    df[[\"SalutForm\",\"FirstName\"]] = df[\"FirstName_tmp\"].str.split(\".\", n=1, expand=True)\n",
    "    \n",
    "    # Grouping family size\n",
    "    df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "    \n",
    "    df[\"Family\"] = None\n",
    "    \n",
    "    df = df.drop([\n",
    "        \"PassengerId\",\n",
    "        \"FirstName_tmp\",\n",
    "        \"Name\",\n",
    "        \"Cabin\",\n",
    "        \"SibSp\",\n",
    "        \"Parch\",\n",
    "        \"Ticket\"], axis=1)\n",
    "                              \n",
    "    return df\n",
    "\n",
    "def group_families_fam_size(df: pd.DataFrame):\n",
    "    for fam in df[\"LastName\"].unique():\n",
    "        tmp_df = df.loc[df[\"LastName\"] == fam ]\n",
    "        \n",
    "        unique_fam_sizes = tmp_df[\"FamilySize\"].unique()\n",
    "        \n",
    "        i = 0\n",
    "        for size in unique_fam_sizes:\n",
    "            df.loc[(df[\"FamilySize\"] == size) & (df[\"LastName\"] == fam), \"Family\"] = f\"{fam}_{i}\"\n",
    "            i = i + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cae2640b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import compose, impute, linear_model, preprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def prepare_data():\n",
    "\n",
    "    # Lade den Trainingsdatensatz\n",
    "    train = pd.read_csv(\"../data/train.csv\")\n",
    "    \n",
    "    # Lade den Kaggle Test Datensatz\n",
    "    # Dieser muss zusammen mit dem Trainingsdatensatz verarbeitet werden, sonst fehlen einige Spalten im Kaggle Testdatensatz!\n",
    "    X_test_kaggle = pd.read_csv(\"../data/test.csv\")\n",
    "    _X_test_kaggle = X_test_kaggle.copy()\n",
    "\n",
    "    X_test_kaggle[\"Survived\"] = 0 # Dummy damit Pandas keine Zicken macht\n",
    "    X_test_kaggle[\"IsKaggleTestData\"] = True\n",
    "    \n",
    "    # Transformiere die Daten mit der ersten Funktion und erstelle eine Spalte um später die Kaggle Testdaten zu extrahiern\n",
    "    train = transform_data(train)\n",
    "    group_families_fam_size(train)\n",
    "    X_test_kaggle = transform_data(X_test_kaggle)\n",
    "    group_families_fam_size(X_test_kaggle)\n",
    "    train[\"IsKaggleTestData\"] = False\n",
    "    \n",
    "    # Kombiniere beide Datensätze, da es ansonsten Probleme mit der Pipeline gibt\n",
    "    df = pd.concat([train, X_test_kaggle], axis=0)\n",
    "    \n",
    "    # Typisiere die Spalten\n",
    "    num_cols = [\"Age\", \"Fare\", \"FamilySize\"]\n",
    "    cat_cols = [\"Pclass\", \"Sex\", \"Embarked\", \"SalutForm\", \"Family\"]\n",
    "    dist_col = [\"IsKaggleTestData\"]\n",
    "    \n",
    "    # Definiere die Pipeline und die verschiedenen Preprocesors\n",
    "    numerical_preprocessor = Pipeline(steps=[\n",
    "        (\"imputer\", impute.SimpleImputer(strategy=\"mean\")),\n",
    "        (\"scaler\", preprocessing.StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_preprocessor = Pipeline(steps=[\n",
    "        (\"imputer\", impute.SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"onehot\", preprocessing.OneHotEncoder(handle_unknown=\"error\", sparse_output=False)),\n",
    "    ])\n",
    "\n",
    "    preprocessor = compose.ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"numerical\", numerical_preprocessor, num_cols),\n",
    "            (\"categorical\", categorical_preprocessor, cat_cols),\n",
    "            (\"passthrough\", \"passthrough\", dist_col)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Löse die Labels von Features ab\n",
    "    y = df[[\"Survived\",\"IsKaggleTestData\"]]\n",
    "    X = df.drop([\"Survived\"], axis=1)\n",
    "    \n",
    "    # Preprocess die Features\n",
    "    preprocessor.set_output(transform=\"pandas\")\n",
    "    X_pipe = preprocessor.fit_transform(X)\n",
    "    \n",
    "    # Löse die Kaggle Testdaten von der Gesamtheit der Features und bereinige diese von der Dummy Spalte\n",
    "    X_test_kaggle_pipe = X_pipe.loc[X_pipe[\"passthrough__IsKaggleTestData\"] == True]\n",
    "    X_test_kaggle_pipe = X_test_kaggle_pipe.drop([\"passthrough__IsKaggleTestData\"], axis = 1)\n",
    "    \n",
    "    # Löse die Trainingsfeatures von der Gesamtheit der Features und bereinige diese von der Dummy Spalte\n",
    "    X_train_full_pipe = X_pipe.loc[X_pipe[\"passthrough__IsKaggleTestData\"] == False]\n",
    "    X_train_full_pipe = X_train_full_pipe.drop([\"passthrough__IsKaggleTestData\"], axis = 1)\n",
    "    \n",
    "    # Trenne die Trainingslabels von den Dummy Labels\n",
    "    y_train_full_pipe = y.loc[y[\"IsKaggleTestData\"] == False]\n",
    "    y_train_full_pipe = y_train_full_pipe.drop([\"IsKaggleTestData\"], axis = 1)\n",
    "    \n",
    "    # Erstelle aus den Trainingsfeatures ein weiteren Testdatensatz, der lokal benutzt wird\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_train_full_pipe, y_train_full_pipe, test_size=0.2)\n",
    "    \n",
    "    # Gebe die lokalen Trainings- und Testdatensätze sowie den Kaggle Testdatensatz zurück\n",
    "    return X_train, X_test, y_train, y_test, X_test_kaggle_pipe, _X_test_kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09c3b783",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, X_test_kaggle_pipe, _X_test_kaggle = prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba6d829e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 712 entries, 522 to 305\n",
      "Columns: 948 entries, numerical__Age to categorical__Family_van Melkebeke_0\n",
      "dtypes: float64(948)\n",
      "memory usage: 5.2 MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c2509a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numerical__Age</th>\n",
       "      <th>numerical__Fare</th>\n",
       "      <th>numerical__FamilySize</th>\n",
       "      <th>categorical__Pclass_1</th>\n",
       "      <th>categorical__Pclass_2</th>\n",
       "      <th>categorical__Pclass_3</th>\n",
       "      <th>categorical__Sex_female</th>\n",
       "      <th>categorical__Sex_male</th>\n",
       "      <th>categorical__Embarked_C</th>\n",
       "      <th>categorical__Embarked_Q</th>\n",
       "      <th>...</th>\n",
       "      <th>categorical__Family_Zabour_0</th>\n",
       "      <th>categorical__Family_Zakarian_0</th>\n",
       "      <th>categorical__Family_Zimmerman_0</th>\n",
       "      <th>categorical__Family_de Brito_0</th>\n",
       "      <th>categorical__Family_de Messemaeker_0</th>\n",
       "      <th>categorical__Family_de Mulder_0</th>\n",
       "      <th>categorical__Family_de Pelsmaeker_0</th>\n",
       "      <th>categorical__Family_del Carlo_0</th>\n",
       "      <th>categorical__Family_van Billiard_0</th>\n",
       "      <th>categorical__Family_van Melkebeke_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.504078</td>\n",
       "      <td>-0.558346</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>1.406933</td>\n",
       "      <td>-0.130425</td>\n",
       "      <td>-0.558346</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>0.785731</td>\n",
       "      <td>1.956811</td>\n",
       "      <td>0.705051</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>-1.466124</td>\n",
       "      <td>1.676450</td>\n",
       "      <td>1.336749</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.491108</td>\n",
       "      <td>-0.558346</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 948 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     numerical__Age  numerical__Fare  numerical__FamilySize  \\\n",
       "522        0.000000        -0.504078              -0.558346   \n",
       "460        1.406933        -0.130425              -0.558346   \n",
       "319        0.785731         1.956811               0.705051   \n",
       "802       -1.466124         1.676450               1.336749   \n",
       "42         0.000000        -0.491108              -0.558346   \n",
       "\n",
       "     categorical__Pclass_1  categorical__Pclass_2  categorical__Pclass_3  \\\n",
       "522                    0.0                    0.0                    1.0   \n",
       "460                    1.0                    0.0                    0.0   \n",
       "319                    1.0                    0.0                    0.0   \n",
       "802                    1.0                    0.0                    0.0   \n",
       "42                     0.0                    0.0                    1.0   \n",
       "\n",
       "     categorical__Sex_female  categorical__Sex_male  categorical__Embarked_C  \\\n",
       "522                      0.0                    1.0                      1.0   \n",
       "460                      0.0                    1.0                      0.0   \n",
       "319                      1.0                    0.0                      1.0   \n",
       "802                      0.0                    1.0                      0.0   \n",
       "42                       0.0                    1.0                      1.0   \n",
       "\n",
       "     categorical__Embarked_Q  ...  categorical__Family_Zabour_0  \\\n",
       "522                      0.0  ...                           0.0   \n",
       "460                      0.0  ...                           0.0   \n",
       "319                      0.0  ...                           0.0   \n",
       "802                      0.0  ...                           0.0   \n",
       "42                       0.0  ...                           0.0   \n",
       "\n",
       "     categorical__Family_Zakarian_0  categorical__Family_Zimmerman_0  \\\n",
       "522                             0.0                              0.0   \n",
       "460                             0.0                              0.0   \n",
       "319                             0.0                              0.0   \n",
       "802                             0.0                              0.0   \n",
       "42                              0.0                              0.0   \n",
       "\n",
       "     categorical__Family_de Brito_0  categorical__Family_de Messemaeker_0  \\\n",
       "522                             0.0                                   0.0   \n",
       "460                             0.0                                   0.0   \n",
       "319                             0.0                                   0.0   \n",
       "802                             0.0                                   0.0   \n",
       "42                              0.0                                   0.0   \n",
       "\n",
       "     categorical__Family_de Mulder_0  categorical__Family_de Pelsmaeker_0  \\\n",
       "522                              0.0                                  0.0   \n",
       "460                              0.0                                  0.0   \n",
       "319                              0.0                                  0.0   \n",
       "802                              0.0                                  0.0   \n",
       "42                               0.0                                  0.0   \n",
       "\n",
       "     categorical__Family_del Carlo_0  categorical__Family_van Billiard_0  \\\n",
       "522                              0.0                                 0.0   \n",
       "460                              0.0                                 0.0   \n",
       "319                              0.0                                 0.0   \n",
       "802                              0.0                                 0.0   \n",
       "42                               0.0                                 0.0   \n",
       "\n",
       "     categorical__Family_van Melkebeke_0  \n",
       "522                                  0.0  \n",
       "460                                  0.0  \n",
       "319                                  0.0  \n",
       "802                                  0.0  \n",
       "42                                   0.0  \n",
       "\n",
       "[5 rows x 948 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204e2923",
   "metadata": {},
   "source": [
    "# Baue die verschiedenen Modelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ddcdf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb957b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter für die Modelle\n",
    "\n",
    "# Random Forest\n",
    "rf_params = {\n",
    "    \"n_jobs\": -1,\n",
    "    \"n_estimators\": 500,\n",
    "     \"warm_start\": True, \n",
    "     #\"max_features\": 0.2,\n",
    "    \"max_depth\": 6,\n",
    "    \"min_samples_leaf\": 2,\n",
    "    \"max_features\" : \"sqrt\",\n",
    "    \"verbose\": 0\n",
    "}\n",
    "\n",
    "# Extra Trees\n",
    "et_params = {\n",
    "    \"n_jobs\": -1,\n",
    "    \"n_estimators\":500,\n",
    "    # \"max_features\": 0.5,\n",
    "    \"max_depth\": 8,\n",
    "    \"min_samples_leaf\": 2,\n",
    "    \"verbose\": 0\n",
    "}\n",
    "\n",
    "# AdaBoost\n",
    "ada_params = {\n",
    "    \"n_estimators\": 500,\n",
    "    \"learning_rate\" : 0.75\n",
    "}\n",
    "\n",
    "# Gradient Boosting\n",
    "gb_params = {\n",
    "    \"n_estimators\": 500,\n",
    "    # \"max_features\": 0.2,\n",
    "    \"max_depth\": 5,\n",
    "    \"min_samples_leaf\": 2,\n",
    "    \"verbose\": 0\n",
    "}\n",
    "\n",
    "# Support Vector Classifier\n",
    "svc_params = {\n",
    "    \"kernel\" : \"linear\",\n",
    "    \"C\" : 0.025\n",
    "}\n",
    "\n",
    "bag_svc_params = {\n",
    "    \"estimator\": SVC(),\n",
    "    \"n_estimators\": 500,\n",
    "    \"max_samples\": 50,\n",
    "    \"bootstrap\": True,\n",
    "    \"n_jobs\": -1\n",
    "}\n",
    "\n",
    "bag_rf_params = {\n",
    "    \"estimator\": RandomForestClassifier(),\n",
    "    \"n_estimators\": 100,\n",
    "    \"max_samples\": 200,\n",
    "    \"bootstrap\": True,\n",
    "    \"n_jobs\": -1\n",
    "}\n",
    "\n",
    "bag_dt_params = {\n",
    "    \"estimator\": DecisionTreeClassifier(),\n",
    "    \"n_estimators\": 100,\n",
    "    \"max_samples\": 200,\n",
    "    \"bootstrap\": True,\n",
    "    \"n_jobs\": -1\n",
    "}\n",
    "\n",
    "# für die Grid Search (siehe weiter unten)\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200, 300],\n",
    "    \"max_samples\": [100, 200, 300],\n",
    "    \"bootstrap\": [False, True]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfbe83ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 5 objects that represent our 4 models\n",
    "rf = RandomForestClassifier(**rf_params)\n",
    "et = ExtraTreesClassifier(**et_params)\n",
    "ada = AdaBoostClassifier(**ada_params)\n",
    "gb = GradientBoostingClassifier(**gb_params)\n",
    "svc = SVC(**svc_params)\n",
    "bag_svc = BaggingClassifier(**bag_svc_params)\n",
    "bag_rf = BaggingClassifier(**bag_rf_params)\n",
    "bag_dt = BaggingClassifier(**bag_dt_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b575fe71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=bag_dt,\n",
    "    param_grid=param_grid,\n",
    "    cv=10,\n",
    "    verbose=1,\n",
    "    scoring=\"accuracy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18ee197a",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"RandomForest\": rf,\n",
    "    \"ExtraTrees\": et,\n",
    "    \"AdaBoost\": ada,\n",
    "    \"GradientBoosting\": gb,\n",
    "    \"SVC\": svc,\n",
    "    \"Bagging_SVC\": bag_svc,\n",
    "    \"Bagging_RandomForest\": bag_rf,\n",
    "    \"Bagging_DecisionTree\": bag_dt,\n",
    "    \"GridSearchBest\": grid_search,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16422e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n"
     ]
    }
   ],
   "source": [
    "# Trainiere sie alle\n",
    "for model in models.values():\n",
    "    model.fit(X_train, y_train.to_numpy().ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8719b183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beste Parameter: {'bootstrap': False, 'max_samples': 200, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Ersetze die Grid Search durch das beste Modell\n",
    "models[\"GridSearchBest\"] = grid_search.best_estimator_\n",
    "print(\"Beste Parameter:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b84c73fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modell: RandomForest\n",
      "Durc. Accuracy: 0.7583965330444205 (cross val. auf Trainingsdatensatz)\n",
      "Accuracy: \t0.7821229050279329 (Testdatensatz)\n",
      "Precision: \t0.9230769230769231 (Testdatensatz)\n",
      "Recall: \t0.5 (Testdatensatz)\n",
      "F1 Score: \t0.6486486486486487 (Testdatensatz) \n",
      "\n",
      "Modell: ExtraTrees\n",
      "Durc. Accuracy: 0.8117206736925047 (cross val. auf Trainingsdatensatz)\n",
      "Accuracy: \t0.7821229050279329 (Testdatensatz)\n",
      "Precision: \t0.8 (Testdatensatz)\n",
      "Recall: \t0.6111111111111112 (Testdatensatz)\n",
      "F1 Score: \t0.6929133858267716 (Testdatensatz) \n",
      "\n",
      "Modell: AdaBoost\n",
      "Durc. Accuracy: 0.835605239830592 (cross val. auf Trainingsdatensatz)\n",
      "Accuracy: \t0.8212290502793296 (Testdatensatz)\n",
      "Precision: \t0.8333333333333334 (Testdatensatz)\n",
      "Recall: \t0.6944444444444444 (Testdatensatz)\n",
      "F1 Score: \t0.7575757575757577 (Testdatensatz) \n",
      "\n",
      "Modell: GradientBoosting\n",
      "Durc. Accuracy: 0.8144981778784596 (cross val. auf Trainingsdatensatz)\n",
      "Accuracy: \t0.8044692737430168 (Testdatensatz)\n",
      "Precision: \t0.7681159420289855 (Testdatensatz)\n",
      "Recall: \t0.7361111111111112 (Testdatensatz)\n",
      "F1 Score: \t0.7517730496453902 (Testdatensatz) \n",
      "\n",
      "Modell: SVC\n",
      "Durc. Accuracy: 0.7948586624642962 (cross val. auf Trainingsdatensatz)\n",
      "Accuracy: \t0.7653631284916201 (Testdatensatz)\n",
      "Precision: \t0.75 (Testdatensatz)\n",
      "Recall: \t0.625 (Testdatensatz)\n",
      "F1 Score: \t0.6818181818181818 (Testdatensatz) \n",
      "\n",
      "Modell: Bagging_SVC\n",
      "Durc. Accuracy: 0.81312912439673 (cross val. auf Trainingsdatensatz)\n",
      "Accuracy: \t0.7932960893854749 (Testdatensatz)\n",
      "Precision: \t0.7868852459016393 (Testdatensatz)\n",
      "Recall: \t0.6666666666666666 (Testdatensatz)\n",
      "F1 Score: \t0.7218045112781954 (Testdatensatz) \n",
      "\n",
      "Modell: Bagging_RandomForest\n",
      "Durc. Accuracy: 0.8384024426277946 (cross val. auf Trainingsdatensatz)\n",
      "Accuracy: \t0.8212290502793296 (Testdatensatz)\n",
      "Precision: \t0.8703703703703703 (Testdatensatz)\n",
      "Recall: \t0.6527777777777778 (Testdatensatz)\n",
      "F1 Score: \t0.746031746031746 (Testdatensatz) \n",
      "\n",
      "Modell: Bagging_DecisionTree\n",
      "Durc. Accuracy: 0.835585541219344 (cross val. auf Trainingsdatensatz)\n",
      "Accuracy: \t0.8044692737430168 (Testdatensatz)\n",
      "Precision: \t0.8363636363636363 (Testdatensatz)\n",
      "Recall: \t0.6388888888888888 (Testdatensatz)\n",
      "F1 Score: \t0.7244094488188975 (Testdatensatz) \n",
      "\n",
      "Modell: GridSearchBest\n",
      "Durc. Accuracy: 0.8440263961390724 (cross val. auf Trainingsdatensatz)\n",
      "Accuracy: \t0.8212290502793296 (Testdatensatz)\n",
      "Precision: \t0.8571428571428571 (Testdatensatz)\n",
      "Recall: \t0.6666666666666666 (Testdatensatz)\n",
      "F1 Score: \t0.75 (Testdatensatz) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from datetime import datetime\n",
    "\n",
    "result_text = \"\"\n",
    "for name, model in models.items():\n",
    "    result = cross_val_score(model, X_train, y_train.to_numpy().ravel(), scoring=\"accuracy\")\n",
    "    mean = sum(result) / len(result)\n",
    "    y_test_predict = model.predict(X_test)\n",
    "\n",
    "    \n",
    "    string = f\"Modell: {name}\"\n",
    "    string = f\"{string}\\nDurc. Accuracy: {mean} (cross val. auf Trainingsdatensatz)\"\n",
    "    string = f\"{string}\\nAccuracy: \\t{accuracy_score(y_test, y_test_predict)} (Testdatensatz)\"\n",
    "    string = f\"{string}\\nPrecision: \\t{precision_score(y_test, y_test_predict)} (Testdatensatz)\"\n",
    "    string = f\"{string}\\nRecall: \\t{recall_score(y_test, y_test_predict)} (Testdatensatz)\"\n",
    "    string = f\"{string}\\nF1 Score: \\t{f1_score(y_test, y_test_predict)} (Testdatensatz)\"\n",
    "    print(string, \"\\n\")\n",
    "    result_text = f\"{result_text}\\n{string}\\n\"\n",
    "    \n",
    "with open(f\"../submissions/{datetime.today().strftime('%Y-%m-%d %H_%M_%S')}_last values.txt\", \"w\") as file:\n",
    "    file.write(result_text)\n",
    "    file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b5fb3a",
   "metadata": {},
   "source": [
    "# =>Bagging (RandomForest) und Bagging (SVC) sind vielversprechend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b179bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vorhersagen für Kaggle\n",
    "\n",
    "name = \"Bagging_RandomForest\"\n",
    "\n",
    "# Check, ob der Name im Dict ist\n",
    "if name not in models.keys():\n",
    "    raise KeyError(f\"Das Modell {name} ist nicht im Dictionary!\")\n",
    "\n",
    "\n",
    "preds_kaggle = models[name].predict(X_test_kaggle_pipe)\n",
    "output = pd.DataFrame({\"PassengerId\": _X_test_kaggle[\"PassengerId\"], \"Survived\": preds_kaggle})\n",
    "output_path = f\"../submissions/{datetime.today().strftime('%Y-%m-%d %H_%M_%S')} {name}.csv\"\n",
    "# output.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e8e92b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
